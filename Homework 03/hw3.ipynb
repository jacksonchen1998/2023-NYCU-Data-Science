{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "with open(\"./train.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f) # a dictionary\n",
    "\n",
    "with open(\"./validation.pkl\", \"rb\") as f:\n",
    "    val = pickle.load(f) # a dictionary\n",
    "    \n",
    "with open(\"./test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f) # a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the size of the train, val, test\n",
    "print(\"Train dataset size\", len(train['images']))\n",
    "print(\"Validation dataset size\", len(val['images']))\n",
    "print(\"Test dataset size\", len(test['qry_images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy comcatenate from train and val\n",
    "new_train = {}\n",
    "new_train['images'] = np.concatenate((train['images'], val['images']), axis=0)\n",
    "new_train['labels'] = np.concatenate((train['labels'], val['labels']), axis=0)\n",
    "print(\"New train dataset size\", len(new_train['images']))\n",
    "print(\"New train dataset shape\", new_train['images'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New train label size\", len(new_train['labels']))\n",
    "print(\"New train label shape\", new_train['labels'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_train['labels'][47999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traversal all new_train['labels'] and calculate the number of each class\n",
    "class_num = {}\n",
    "for i in range(new_train['labels'].shape[0]):\n",
    "    if new_train['labels'][i] in class_num:\n",
    "        class_num[new_train['labels'][i]] += 1\n",
    "    else:\n",
    "        class_num[new_train['labels'][i]] = 1\n",
    "print(\"Class number\", len(class_num))\n",
    "print(\"Class number\", class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = torchvision.transforms.ToPILImage()\n",
    "# img2 = transform(torch.tensor(new_train[\"images\"][38400])*255)\n",
    "# img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation for train\n",
    "\n",
    "# set device as gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "        [transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(p=0.15),\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "        [transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# doing data augmentation for train[\"images\"]\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.tensor(new_train[\"images\"]).float().to(device), torch.tensor(new_train[\"labels\"]).long().to(device))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.tensor(val[\"images\"]).float().to(device), torch.tensor(val[\"labels\"]).long().to(device))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the size of the train_loader\n",
    "print(\"Train loader size\", len(train_loader))\n",
    "print(\"Validation loader size\", len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = torch.nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                torch.nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample is not None: # identity mapping used\n",
    "            identity = self.downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class ResNet18(torch.nn.Module):\n",
    "    def __init__(self, num_classes=80):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer1 = self._make_layer(64, 64, 2)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2) \n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = torch.nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, block_num, stride=1):\n",
    "        layers = []\n",
    "        layers.append(ResNetBlock(in_channels, out_channels, stride=stride))\n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResNetBlock(out_channels, out_channels))\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with train_loader and test the model with val_loader\n",
    "\n",
    "model = ResNet18().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1280, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_epoch = 100\n",
    "\n",
    "for epoch in range(train_epoch):\n",
    "    print('Epoch', epoch)\n",
    "    train_loss_sum = 0\n",
    "    train_acc_sum = 0\n",
    "    \n",
    "    model.train()\n",
    "    #train_loop = tqdm.tqdm((train_loader), total=len(train_loader), leave=False)\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # move data and target to device\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = criterion(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        train_loss_sum += loss.item()\n",
    "        train_acc_sum += (predicted == target.to(device)).sum().item()\n",
    "    print('Train Accuracy', train_acc_sum / len(train_loader.dataset))\n",
    "    print('Train Loss', train_loss_sum / len(train_loader.dataset))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss_sum = 0\n",
    "    val_acc_sum = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(val_loader):\n",
    "        output = model(data.to(device))\n",
    "        loss = criterion(output, target.to(device))\n",
    "        val_loss_sum += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        val_acc_sum += (predicted == target.to(device)).sum().item()\n",
    "    print('Validation Accuracy', val_acc_sum / len(val_loader.dataset))\n",
    "    print('Validation Loss', val_loss_sum / len(val_loader.dataset))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
